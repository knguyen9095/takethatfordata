// A passthrough read/write stream that sets its properties
// based on a header, extendedHeader, and globalHeader
//
// Can be either a file system object of some sort, or
// a pax/ustar metadata entry.

module.exports = Entry

var TarHeader = require("./header.js")
  , tar = require("../tar")
  , assert = require("assert").ok
  , Stream = require("stream").Stream
  , inherits = require("inherits")
  , fstream = require("fstream").Abstract

function Entry (header, extended, global) ***REMOVED***
  Stream.call(this)
  this.readable = true
  this.writable = true

  this._needDrain = false
  this._paused = false
  this._reading = false
  this._ending = false
  this._ended = false
  this._remaining = 0
  this._abort = false
  this._queue = []
  this._index = 0
  this._queueLen = 0

  this._read = this._read.bind(this)

  this.props = ***REMOVED******REMOVED***
  this._header = header
  this._extended = extended || ***REMOVED******REMOVED***

  // globals can change throughout the course of
  // a file parse operation.  Freeze it at its current state.
  this._global = ***REMOVED******REMOVED***
  var me = this
  Object.keys(global || ***REMOVED******REMOVED***).forEach(function (g) ***REMOVED***
    me._global[g] = global[g]
  ***REMOVED***)

  this._setProps()
***REMOVED***

inherits(Entry, Stream)

Entry.prototype.write = function (c) ***REMOVED***
  if (this._ending) this.error("write() after end()", null, true)
  if (this._remaining === 0) ***REMOVED***
    this.error("invalid bytes past eof")
  ***REMOVED***

  // often we'll get a bunch of \0 at the end of the last write,
  // since chunks will always be 512 bytes when reading a tarball.
  if (c.length > this._remaining) ***REMOVED***
    c = c.slice(0, this._remaining)
  ***REMOVED***
  this._remaining -= c.length

  // put it on the stack.
  var ql = this._queueLen
  this._queue.push(c)
  this._queueLen ++

  this._read()

  // either paused, or buffered
  if (this._paused || ql > 0) ***REMOVED***
    this._needDrain = true
    return false
  ***REMOVED***

  return true
***REMOVED***

Entry.prototype.end = function (c) ***REMOVED***
  if (c) this.write(c)
  this._ending = true
  this._read()
***REMOVED***

Entry.prototype.pause = function () ***REMOVED***
  this._paused = true
  this.emit("pause")
***REMOVED***

Entry.prototype.resume = function () ***REMOVED***
  // console.error("    Tar Entry resume", this.path)
  this.emit("resume")
  this._paused = false
  this._read()
  return this._queueLen - this._index > 1
***REMOVED***

  // This is bound to the instance
Entry.prototype._read = function () ***REMOVED***
  // console.error("    Tar Entry _read", this.path)

  if (this._paused || this._reading || this._ended) return

  // set this flag so that event handlers don't inadvertently
  // get multiple _read() calls running.
  this._reading = true

  // have any data to emit?
  while (this._index < this._queueLen && !this._paused) ***REMOVED***
    var chunk = this._queue[this._index ++]
    this.emit("data", chunk)
  ***REMOVED***

  // check if we're drained
  if (this._index >= this._queueLen) ***REMOVED***
    this._queue.length = this._queueLen = this._index = 0
    if (this._needDrain) ***REMOVED***
      this._needDrain = false
      this.emit("drain")
    ***REMOVED***
    if (this._ending) ***REMOVED***
      this._ended = true
      this.emit("end")
    ***REMOVED***
  ***REMOVED***

  // if the queue gets too big, then pluck off whatever we can.
  // this should be fairly rare.
  var mql = this._maxQueueLen
  if (this._queueLen > mql && this._index > 0) ***REMOVED***
    mql = Math.min(this._index, mql)
    this._index -= mql
    this._queueLen -= mql
    this._queue = this._queue.slice(mql)
  ***REMOVED***

  this._reading = false
***REMOVED***

Entry.prototype._setProps = function () ***REMOVED***
  // props = extended->global->header->***REMOVED******REMOVED***
  var header = this._header
    , extended = this._extended
    , global = this._global
    , props = this.props

  // first get the values from the normal header.
  var fields = tar.fields
  for (var f = 0; fields[f] !== null; f ++) ***REMOVED***
    var field = fields[f]
      , val = header[field]
    if (typeof val !== "undefined") props[field] = val
  ***REMOVED***

  // next, the global header for this file.
  // numeric values, etc, will have already been parsed.
  ;[global, extended].forEach(function (p) ***REMOVED***
    Object.keys(p).forEach(function (f) ***REMOVED***
      if (typeof p[f] !== "undefined") props[f] = p[f]
    ***REMOVED***)
  ***REMOVED***)

  // no nulls allowed in path or linkpath
  ;["path", "linkpath"].forEach(function (p) ***REMOVED***
    if (props.hasOwnProperty(p)) ***REMOVED***
      props[p] = props[p].split("\0")[0]
    ***REMOVED***
  ***REMOVED***)


  // set date fields to be a proper date
  ;["mtime", "ctime", "atime"].forEach(function (p) ***REMOVED***
    if (props.hasOwnProperty(p)) ***REMOVED***
      props[p] = new Date(props[p] * 1000)
    ***REMOVED***
  ***REMOVED***)

  // set the type so that we know what kind of file to create
  var type
  switch (tar.types[props.type]) ***REMOVED***
    case "OldFile":
    case "ContiguousFile":
      type = "File"
      break

    case "GNUDumpDir":
      type = "Directory"
      break

    case undefined:
      type = "Unknown"
      break

    case "Link":
    case "SymbolicLink":
    case "CharacterDevice":
    case "BlockDevice":
    case "Directory":
    case "FIFO":
    default:
      type = tar.types[props.type]
  ***REMOVED***

  this.type = type
  this.path = props.path
  this.size = props.size

  // size is special, since it signals when the file needs to end.
  this._remaining = props.size
***REMOVED***

// the parser may not call write if _abort is true. 
// useful for skipping data from some files quickly.
Entry.prototype.abort = function()***REMOVED***
  this._abort = true
***REMOVED***

Entry.prototype.warn = fstream.warn
Entry.prototype.error = fstream.error

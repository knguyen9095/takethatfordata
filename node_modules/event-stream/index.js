//filter will reemit the data if cb(err,pass) pass is truthy

// reduce is more tricky
// maybe we want to group the reductions or emit progress updates occasionally
// the most basic reduce just emits one 'data' event after it has recieved 'end'

var Stream = require('stream').Stream
  , es = exports
  , through = require('through')
  , from = require('from')
  , duplex = require('duplexer')
  , map = require('map-stream')
  , pause = require('pause-stream')
  , split = require('split')
  , pipeline = require('stream-combiner')
  , immediately = global.setImmediate || process.nextTick;

es.Stream = Stream //re-export Stream from core
es.through = through
es.from = from
es.duplex = duplex
es.map = map
es.pause = pause
es.split = split
es.pipeline = es.connect = es.pipe = pipeline
// merge / concat
//
// combine multiple streams into a single stream.
// will emit end only once

es.concat = //actually this should be called concat
es.merge = function (/*streams...*/) ***REMOVED***
  var toMerge = [].slice.call(arguments)
  if (toMerge.length === 1 && (toMerge[0] instanceof Array)) ***REMOVED***
    toMerge = toMerge[0] //handle array as arguments object
  ***REMOVED***
  var stream = new Stream()
  stream.setMaxListeners(0) // allow adding more than 11 streams
  var endCount = 0
  stream.writable = stream.readable = true

  if (toMerge.length) ***REMOVED***
    toMerge.forEach(function (e) ***REMOVED***
      e.pipe(stream, ***REMOVED***end: false***REMOVED***)
      var ended = false
      e.on('end', function () ***REMOVED***
        if(ended) return
        ended = true
        endCount ++
        if(endCount == toMerge.length)
          stream.emit('end')
      ***REMOVED***)
    ***REMOVED***)
  ***REMOVED*** else ***REMOVED***
    process.nextTick(function () ***REMOVED***
      stream.emit('end')
    ***REMOVED***)
  ***REMOVED***
  
  stream.write = function (data) ***REMOVED***
    this.emit('data', data)
  ***REMOVED***
  stream.destroy = function () ***REMOVED***
    toMerge.forEach(function (e) ***REMOVED***
      if(e.destroy) e.destroy()
    ***REMOVED***)
  ***REMOVED***
  return stream
***REMOVED***


// writable stream, collects all events into an array
// and calls back when 'end' occurs
// mainly I'm using this to test the other functions

es.writeArray = function (done) ***REMOVED***
  if ('function' !== typeof done)
    throw new Error('function writeArray (done): done must be function')

  var a = new Stream ()
    , array = [], isDone = false
  a.write = function (l) ***REMOVED***
    array.push(l)
  ***REMOVED***
  a.end = function () ***REMOVED***
    isDone = true
    done(null, array)
  ***REMOVED***
  a.writable = true
  a.readable = false
  a.destroy = function () ***REMOVED***
    a.writable = a.readable = false
    if(isDone) return
    done(new Error('destroyed before end'), array)
  ***REMOVED***
  return a
***REMOVED***

//return a Stream that reads the properties of an object
//respecting pause() and resume()

es.readArray = function (array) ***REMOVED***
  var stream = new Stream()
    , i = 0
    , paused = false
    , ended = false

  stream.readable = true
  stream.writable = false

  if(!Array.isArray(array))
    throw new Error('event-stream.read expects an array')

  stream.resume = function () ***REMOVED***
    if(ended) return
    paused = false
    var l = array.length
    while(i < l && !paused && !ended) ***REMOVED***
      stream.emit('data', array[i++])
    ***REMOVED***
    if(i == l && !ended)
      ended = true, stream.readable = false, stream.emit('end')
  ***REMOVED***
  process.nextTick(stream.resume)
  stream.pause = function () ***REMOVED***
     paused = true
  ***REMOVED***
  stream.destroy = function () ***REMOVED***
    ended = true
    stream.emit('close')
  ***REMOVED***
  return stream
***REMOVED***

//
// readable (asyncFunction)
// return a stream that calls an async function while the stream is not paused.
//
// the function must take: (count, callback) ***REMOVED***...
//

es.readable =
function (func, continueOnError) ***REMOVED***
  var stream = new Stream()
    , i = 0
    , paused = false
    , ended = false
    , reading = false

  stream.readable = true
  stream.writable = false

  if('function' !== typeof func)
    throw new Error('event-stream.readable expects async function')

  stream.on('end', function () ***REMOVED*** ended = true ***REMOVED***)

  function get (err, data) ***REMOVED***

    if(err) ***REMOVED***
      stream.emit('error', err)
      if(!continueOnError) stream.emit('end')
    ***REMOVED*** else if (arguments.length > 1)
      stream.emit('data', data)

    immediately(function () ***REMOVED***
      if(ended || paused || reading) return
      try ***REMOVED***
        reading = true
        func.call(stream, i++, function () ***REMOVED***
          reading = false
          get.apply(null, arguments)
        ***REMOVED***)
      ***REMOVED*** catch (err) ***REMOVED***
        stream.emit('error', err)
      ***REMOVED***
    ***REMOVED***)
  ***REMOVED***
  stream.resume = function () ***REMOVED***
    paused = false
    get()
  ***REMOVED***
  process.nextTick(get)
  stream.pause = function () ***REMOVED***
     paused = true
  ***REMOVED***
  stream.destroy = function () ***REMOVED***
    stream.emit('end')
    stream.emit('close')
    ended = true
  ***REMOVED***
  return stream
***REMOVED***


//
// map sync
//

es.mapSync = function (sync) ***REMOVED***
  return es.through(function write(data) ***REMOVED***
    var mappedData
    try ***REMOVED***
      mappedData = sync(data)
    ***REMOVED*** catch (err) ***REMOVED***
      return this.emit('error', err)
    ***REMOVED***
    if (mappedData !== undefined)
      this.emit('data', mappedData)
  ***REMOVED***)
***REMOVED***

//
// log just print out what is coming through the stream, for debugging
//

es.log = function (name) ***REMOVED***
  return es.through(function (data) ***REMOVED***
    var args = [].slice.call(arguments)
    if(name) console.error(name, data)
    else     console.error(data)
    this.emit('data', data)
  ***REMOVED***)
***REMOVED***


//
// child -- pipe through a child process
//

es.child = function (child) ***REMOVED***

  return es.duplex(child.stdin, child.stdout)

***REMOVED***

//
// parse
//
// must be used after es.split() to ensure that each chunk represents a line
// source.pipe(es.split()).pipe(es.parse())

es.parse = function (options) ***REMOVED***
  var emitError = !!(options ? options.error : false)
  return es.through(function (data) ***REMOVED***
    var obj
    try ***REMOVED***
      if(data) //ignore empty lines
        obj = JSON.parse(data.toString())
    ***REMOVED*** catch (err) ***REMOVED***
      if (emitError)
        return this.emit('error', err)
      return console.error(err, 'attempting to parse:', data)
    ***REMOVED***
    //ignore lines that where only whitespace.
    if(obj !== undefined)
      this.emit('data', obj)
  ***REMOVED***)
***REMOVED***
//
// stringify
//

es.stringify = function () ***REMOVED***
  var Buffer = require('buffer').Buffer
  return es.mapSync(function (e)***REMOVED***
    return JSON.stringify(Buffer.isBuffer(e) ? e.toString() : e) + '\n'
  ***REMOVED***)
***REMOVED***

//
// replace a string within a stream.
//
// warn: just concatenates the string and then does str.split().join().
// probably not optimal.
// for smallish responses, who cares?
// I need this for shadow-npm so it's only relatively small json files.

es.replace = function (from, to) ***REMOVED***
  return es.pipeline(es.split(from), es.join(to))
***REMOVED***

//
// join chunks with a joiner. just like Array#join
// also accepts a callback that is passed the chunks appended together
// this is still supported for legacy reasons.
//

es.join = function (str) ***REMOVED***

  //legacy api
  if('function' === typeof str)
    return es.wait(str)

  var first = true
  return es.through(function (data) ***REMOVED***
    if(!first)
      this.emit('data', str)
    first = false
    this.emit('data', data)
    return true
  ***REMOVED***)
***REMOVED***


//
// wait. callback when 'end' is emitted, with all chunks appended as string.
//

es.wait = function (callback) ***REMOVED***
  var arr = []
  return es.through(function (data) ***REMOVED*** arr.push(data) ***REMOVED***,
    function () ***REMOVED***
      var body = Buffer.isBuffer(arr[0]) ? Buffer.concat(arr)
        : arr.join('')
      this.emit('data', body)
      this.emit('end')
      if(callback) callback(null, body)
    ***REMOVED***)
***REMOVED***

es.pipeable = function () ***REMOVED***
  throw new Error('[EVENT-STREAM] es.pipeable is deprecated')
***REMOVED***
